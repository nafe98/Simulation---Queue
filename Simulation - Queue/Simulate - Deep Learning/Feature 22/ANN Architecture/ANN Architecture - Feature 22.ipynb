{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "850c16d8-b28b-4a32-9b28-d05ce5f92685",
   "metadata": {},
   "source": [
    "# Loading the Preprocessed Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "31b9dbdf-69eb-4edd-8fad-7524ce2e3eee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "\n",
    "# Load the arrays\n",
    "X_train = np.load('../Dataset/Train Test Dataset - Feature 22/X_train.npy')\n",
    "X_test = np.load('../Dataset/Train Test Dataset - Feature 22/X_test.npy')\n",
    "y_train = np.load('../Dataset/Train Test Dataset - Feature 22/y_train.npy')\n",
    "y_test = np.load('../Dataset/Train Test Dataset - Feature 22/y_test.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d9b3a01",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #cce5ff; padding: 10px; border: 1px solid #0066cc;\">\n",
    "    <h2 style=\"color: #0066cc; font-weight: bold;\">Deep Learning Architecture - ANN</h2>\n",
    "    \n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c92ddfc",
   "metadata": {},
   "source": [
    "# Importing Libraries - Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c5f6fce3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.models import Sequential\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.callbacks import LearningRateScheduler\n",
    "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization, LeakyReLU"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b262f18",
   "metadata": {},
   "source": [
    "# 1. Network Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "80a9eccd",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = X_train.shape[1]  \n",
    "\n",
    "batch_size = 1024 \n",
    "epochs = 500  \n",
    "learning_rate = 0.0001  \n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=30, restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7fac21c",
   "metadata": {},
   "source": [
    "# 2. Define Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a86494ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "ann_model = Sequential([\n",
    "    \n",
    "    Dense(2048, input_dim=input_dim, activation='relu'),\n",
    "    Dense(1024, activation='relu'),\n",
    "    Dense(512, activation='relu'),\n",
    "    Dense(256, activation='relu'),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(1, activation='sigmoid') \n",
    "    \n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "506b8f43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 2048)              47104     \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1024)              2098176   \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 512)               524800    \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 256)               131328    \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 128)               32896     \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 64)                8256      \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,842,625\n",
      "Trainable params: 2,842,625\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "ann_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb635684",
   "metadata": {},
   "source": [
    "# 3. Model Compilation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3664aa44",
   "metadata": {},
   "outputs": [],
   "source": [
    "ann_model.compile(optimizer=Adam(learning_rate=learning_rate), loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9439e197-2081-4533-aaf0-9660cc5478a9",
   "metadata": {},
   "source": [
    "# EarlyStopping Callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "479588bc-6931-4acb-9815-6418dd0a0ea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b0f2e121-372a-440a-8ed9-a93ced5a4e7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping = EarlyStopping(monitor='val_loss', patience=30, restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a73587dc-8d06-46db-a89a-78ed82e40529",
   "metadata": {},
   "source": [
    "# Model Checkpoints Callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e385d0bd-ca41-4fc3-8008-b4dbaf24dd72",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from keras.models import load_model\n",
    "from keras.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fa7a7c5f-0367-4193-886e-cdd480311858",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_path = '/Model Checkpoints/ANN_Model_Checkpoint.h5'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9782880-c911-4f94-8b72-9627898befcd",
   "metadata": {},
   "source": [
    "### Check if the checkpoint file exists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b7374318-41e3-47b3-8471-953bf0d55b8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint not found. Initializing new model...\n"
     ]
    }
   ],
   "source": [
    "if os.path.exists(checkpoint_path):\n",
    "    print(\"Loading model from checkpoint...\")\n",
    "    model = load_model(checkpoint_path)\n",
    "else:\n",
    "    print(\"Checkpoint not found. Initializing new model...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f0d5b28-9835-4de8-b45c-348ea93f4e3c",
   "metadata": {},
   "source": [
    "### Create the checkpoint callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bb7b1f23-0dd1-4b4c-8b63-2f6f31d6b3f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = ModelCheckpoint(\n",
    "    filepath=checkpoint_path, \n",
    "    monitor='val_loss', \n",
    "    verbose=1, \n",
    "    save_best_only=True, \n",
    "    mode='min'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4fe5fb9",
   "metadata": {},
   "source": [
    "# 4. Fit Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b209aa25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "541/546 [============================>.] - ETA: 0s - loss: 0.5426 - accuracy: 0.7152\n",
      "Epoch 1: val_loss improved from inf to 0.45284, saving model to /Model Checkpoints\\ANN_Model_Checkpoint.h5\n",
      "546/546 [==============================] - 4s 6ms/step - loss: 0.5420 - accuracy: 0.7158 - val_loss: 0.4528 - val_accuracy: 0.7853\n",
      "Epoch 2/500\n",
      "277/546 [==============>...............] - ETA: 1s - loss: 0.4145 - accuracy: 0.8061"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m----> 3\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mann_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[43m                         \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[43m                         \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[43m                         \u001b[49m\u001b[43mvalidation_split\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[43m                         \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mcheckpoint\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mearly_stopping\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[43m                         \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     10\u001b[0m end_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m     12\u001b[0m training_time \u001b[38;5;241m=\u001b[39m end_time \u001b[38;5;241m-\u001b[39m start_time\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\gpu\\lib\\site-packages\\keras\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\gpu\\lib\\site-packages\\keras\\engine\\training.py:1564\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1556\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[0;32m   1557\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1558\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1561\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[0;32m   1562\u001b[0m ):\n\u001b[0;32m   1563\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1564\u001b[0m     tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1565\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[0;32m   1566\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\gpu\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\gpu\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    912\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    914\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 915\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    917\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    918\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\gpu\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:947\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    944\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m    945\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[0;32m    946\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[1;32m--> 947\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stateless_fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)  \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[0;32m    948\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stateful_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    949\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[0;32m    950\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[0;32m    951\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\gpu\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:2496\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2493\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m   2494\u001b[0m   (graph_function,\n\u001b[0;32m   2495\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[1;32m-> 2496\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2497\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\gpu\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:1862\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1858\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1859\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1860\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1861\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1862\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1863\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcancellation_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcancellation_manager\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m   1864\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1865\u001b[0m     args,\n\u001b[0;32m   1866\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1867\u001b[0m     executing_eagerly)\n\u001b[0;32m   1868\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\gpu\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:499\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    497\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _InterpolateFunctionError(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    498\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m cancellation_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 499\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    500\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    501\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_num_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    502\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    503\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    504\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    505\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    506\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m    507\u001b[0m         \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msignature\u001b[38;5;241m.\u001b[39mname),\n\u001b[0;32m    508\u001b[0m         num_outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    511\u001b[0m         ctx\u001b[38;5;241m=\u001b[39mctx,\n\u001b[0;32m    512\u001b[0m         cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_manager)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\gpu\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 54\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     55\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     57\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 115/500\n",
      "546/546 [==============================] - 3s 5ms/step - loss: 0.2848 - accuracy: 0.8703 - val_loss: 0.3969 - val_accuracy: 0.8143\n",
      "Epoch 116/500\n",
      "546/546 [==============================] - 3s 5ms/step - loss: 0.2834 - accuracy: 0.8711 - val_loss: 0.3578 - val_accuracy: 0.8358\n",
      "Epoch 117/500\n",
      "546/546 [==============================] - 3s 5ms/step - loss: 0.2826 - accuracy: 0.8715 - val_loss: 0.3715 - val_accuracy: 0.8321\n",
      "Epoch 118/500\n",
      "546/546 [==============================] - 3s 5ms/step - loss: 0.2850 - accuracy: 0.8705 - val_loss: 0.3647 - val_accuracy: 0.8347\n",
      "Epoch 119/500\n",
      "546/546 [==============================] - 3s 5ms/step - loss: 0.2773 - accuracy: 0.8747 - val_loss: 0.3758 - val_accuracy: 0.8305\n",
      "Epoch 120/500\n",
      "546/546 [==============================] - 3s 5ms/step - loss: 0.2773 - accuracy: 0.8743 - val_loss: 0.3666 - val_accuracy: 0.8323\n",
      "Epoch 121/500\n",
      "546/546 [==============================] - 3s 5ms/step - loss: 0.2776 - accuracy: 0.8742 - val_loss: 0.3578 - val_accuracy: 0.8368\n",
      "Epoch 122/500\n",
      "546/546 [==============================] - 3s 5ms/step - loss: 0.2796 - accuracy: 0.8732 - val_loss: 0.3632 - val_accuracy: 0.8339\n",
      "Epoch 123/500\n",
      "546/546 [==============================] - 3s 5ms/step - loss: 0.2726 - accuracy: 0.8766 - val_loss: 0.3737 - val_accuracy: 0.8332\n",
      "Epoch 124/500\n",
      "546/546 [==============================] - 3s 5ms/step - loss: 0.2763 - accuracy: 0.8748 - val_loss: 0.3888 - val_accuracy: 0.8185\n",
      "Epoch 125/500\n",
      "546/546 [==============================] - 3s 5ms/step - loss: 0.2759 - accuracy: 0.8752 - val_loss: 0.3674 - val_accuracy: 0.8340\n",
      "Epoch 126/500\n",
      "546/546 [==============================] - 3s 5ms/step - loss: 0.2729 - accuracy: 0.8765 - val_loss: 0.3616 - val_accuracy: 0.8376\n",
      "Epoch 127/500\n",
      "546/546 [==============================] - 3s 5ms/step - loss: 0.2713 - accuracy: 0.8778 - val_loss: 0.3629 - val_accuracy: 0.8329\n",
      "Epoch 128/500\n",
      "546/546 [==============================] - 3s 5ms/step - loss: 0.2708 - accuracy: 0.8780 - val_loss: 0.3644 - val_accuracy: 0.8347\n",
      "Epoch 129/500\n",
      "546/546 [==============================] - 3s 5ms/step - loss: 0.2680 - accuracy: 0.8794 - val_loss: 0.3693 - val_accuracy: 0.8343\n",
      "Epoch 130/500\n",
      "546/546 [==============================] - 3s 5ms/step - loss: 0.2713 - accuracy: 0.8777 - val_loss: 0.3713 - val_accuracy: 0.8346\n",
      "Epoch 131/500\n",
      "546/546 [==============================] - 3s 5ms/step - loss: 0.2677 - accuracy: 0.8800 - val_loss: 0.3601 - val_accuracy: 0.8388\n",
      "Epoch 132/500\n",
      "546/546 [==============================] - 3s 5ms/step - loss: 0.2667 - accuracy: 0.8797 - val_loss: 0.3980 - val_accuracy: 0.8176\n",
      "Epoch 133/500\n",
      "546/546 [==============================] - 3s 5ms/step - loss: 0.2644 - accuracy: 0.8816 - val_loss: 0.3580 - val_accuracy: 0.8389\n",
      "Epoch 134/500\n",
      "546/546 [==============================] - 3s 5ms/step - loss: 0.2656 - accuracy: 0.8805 - val_loss: 0.3677 - val_accuracy: 0.8341\n",
      "Epoch 135/500\n",
      "546/546 [==============================] - 3s 5ms/step - loss: 0.2619 - accuracy: 0.8825 - val_loss: 0.3725 - val_accuracy: 0.8338\n",
      "Epoch 136/500\n",
      "546/546 [==============================] - 3s 5ms/step - loss: 0.2639 - accuracy: 0.8811 - val_loss: 0.3628 - val_accuracy: 0.8404\n",
      "Epoch 137/500\n",
      "546/546 [==============================] - 3s 5ms/step - loss: 0.2633 - accuracy: 0.8815 - val_loss: 0.3664 - val_accuracy: 0.8381\n",
      "Epoch 138/500\n",
      "546/546 [==============================] - 3s 5ms/step - loss: 0.2588 - accuracy: 0.8836 - val_loss: 0.3511 - val_accuracy: 0.8425\n",
      "Epoch 139/500\n",
      "546/546 [==============================] - 3s 5ms/step - loss: 0.2591 - accuracy: 0.8845 - val_loss: 0.3514 - val_accuracy: 0.8441\n",
      "Epoch 140/500\n",
      "546/546 [==============================] - 3s 5ms/step - loss: 0.2591 - accuracy: 0.8838 - val_loss: 0.3505 - val_accuracy: 0.8445\n",
      "Epoch 141/500\n",
      "546/546 [==============================] - 3s 5ms/step - loss: 0.2576 - accuracy: 0.8847 - val_loss: 0.3427 - val_accuracy: 0.8466\n",
      "Epoch 142/500\n",
      "546/546 [==============================] - 3s 5ms/step - loss: 0.2579 - accuracy: 0.8846 - val_loss: 0.3613 - val_accuracy: 0.8426\n",
      "Epoch 143/500\n",
      "546/546 [==============================] - 3s 5ms/step - loss: 0.2553 - accuracy: 0.8861 - val_loss: 0.3691 - val_accuracy: 0.8368\n",
      "Epoch 144/500\n",
      "546/546 [==============================] - 3s 5ms/step - loss: 0.2506 - accuracy: 0.8884 - val_loss: 0.3799 - val_accuracy: 0.8327\n",
      "Epoch 145/500\n",
      "546/546 [==============================] - 3s 5ms/step - loss: 0.2546 - accuracy: 0.8855 - val_loss: 0.3674 - val_accuracy: 0.8323\n",
      "Epoch 146/500\n",
      "546/546 [==============================] - 3s 5ms/step - loss: 0.2533 - accuracy: 0.8872 - val_loss: 0.3976 - val_accuracy: 0.8244\n",
      "Epoch 147/500\n",
      "546/546 [==============================] - 3s 5ms/step - loss: 0.2515 - accuracy: 0.8876 - val_loss: 0.3606 - val_accuracy: 0.8377\n",
      "Epoch 148/500\n",
      "546/546 [==============================] - 3s 5ms/step - loss: 0.2494 - accuracy: 0.8886 - val_loss: 0.3561 - val_accuracy: 0.8449\n",
      "Epoch 149/500\n",
      "546/546 [==============================] - 3s 5ms/step - loss: 0.2507 - accuracy: 0.8881 - val_loss: 0.3398 - val_accuracy: 0.8490\n",
      "Epoch 150/500\n",
      "546/546 [==============================] - 3s 5ms/step - loss: 0.2458 - accuracy: 0.8911 - val_loss: 0.3666 - val_accuracy: 0.8367\n",
      "Epoch 151/500\n",
      "546/546 [==============================] - 3s 5ms/step - loss: 0.2464 - accuracy: 0.8904 - val_loss: 0.3613 - val_accuracy: 0.8435\n",
      "Epoch 152/500\n",
      "546/546 [==============================] - 3s 5ms/step - loss: 0.2463 - accuracy: 0.8907 - val_loss: 0.3488 - val_accuracy: 0.8485\n",
      "Epoch 153/500\n",
      "546/546 [==============================] - 3s 5ms/step - loss: 0.2461 - accuracy: 0.8904 - val_loss: 0.3477 - val_accuracy: 0.8468\n",
      "Epoch 154/500\n",
      "546/546 [==============================] - 3s 5ms/step - loss: 0.2449 - accuracy: 0.8911 - val_loss: 0.3712 - val_accuracy: 0.8368\n",
      "Epoch 155/500\n",
      "546/546 [==============================] - 3s 5ms/step - loss: 0.2457 - accuracy: 0.8911 - val_loss: 0.3759 - val_accuracy: 0.8368\n",
      "Epoch 156/500\n",
      "546/546 [==============================] - 3s 5ms/step - loss: 0.2425 - accuracy: 0.8925 - val_loss: 0.3332 - val_accuracy: 0.8529\n",
      "Epoch 157/500\n",
      "546/546 [==============================] - 3s 5ms/step - loss: 0.2421 - accuracy: 0.8927 - val_loss: 0.3369 - val_accuracy: 0.8502\n",
      "Epoch 158/500\n",
      "546/546 [==============================] - 3s 5ms/step - loss: 0.2431 - accuracy: 0.8923 - val_loss: 0.3388 - val_accuracy: 0.8524\n",
      "Epoch 159/500\n",
      "546/546 [==============================] - 3s 5ms/step - loss: 0.2386 - accuracy: 0.8943 - val_loss: 0.3376 - val_accuracy: 0.8551\n",
      "Epoch 160/500\n",
      "546/546 [==============================] - 3s 5ms/step - loss: 0.2355 - accuracy: 0.8959 - val_loss: 0.3467 - val_accuracy: 0.8507\n",
      "Epoch 161/500\n",
      "546/546 [==============================] - 3s 5ms/step - loss: 0.2429 - accuracy: 0.8920 - val_loss: 0.3529 - val_accuracy: 0.8498\n",
      "Epoch 162/500\n",
      "546/546 [==============================] - 3s 5ms/step - loss: 0.2359 - accuracy: 0.8956 - val_loss: 0.3505 - val_accuracy: 0.8476\n",
      "Epoch 163/500\n",
      "546/546 [==============================] - 3s 5ms/step - loss: 0.2409 - accuracy: 0.8931 - val_loss: 0.3509 - val_accuracy: 0.8458\n",
      "Epoch 164/500\n",
      "546/546 [==============================] - 3s 5ms/step - loss: 0.2338 - accuracy: 0.8970 - val_loss: 0.3523 - val_accuracy: 0.8478\n",
      "Epoch 165/500\n",
      "546/546 [==============================] - 3s 5ms/step - loss: 0.2323 - accuracy: 0.8975 - val_loss: 0.3449 - val_accuracy: 0.8492\n",
      "Epoch 166/500\n",
      "546/546 [==============================] - 3s 5ms/step - loss: 0.2333 - accuracy: 0.8965 - val_loss: 0.3529 - val_accuracy: 0.8487\n",
      "Epoch 167/500\n",
      "546/546 [==============================] - 3s 5ms/step - loss: 0.2329 - accuracy: 0.8968 - val_loss: 0.3392 - val_accuracy: 0.8548\n",
      "Epoch 168/500\n",
      "546/546 [==============================] - 2s 4ms/step - loss: 0.2331 - accuracy: 0.8967 - val_loss: 0.3486 - val_accuracy: 0.8469\n",
      "Epoch 169/500\n",
      "546/546 [==============================] - 3s 5ms/step - loss: 0.2338 - accuracy: 0.8969 - val_loss: 0.3380 - val_accuracy: 0.8525\n",
      "Epoch 170/500\n",
      "546/546 [==============================] - 3s 5ms/step - loss: 0.2277 - accuracy: 0.8999 - val_loss: 0.3385 - val_accuracy: 0.8544\n",
      "Epoch 171/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "546/546 [==============================] - 3s 5ms/step - loss: 0.2294 - accuracy: 0.8992 - val_loss: 0.3498 - val_accuracy: 0.8500\n",
      "Epoch 172/500\n",
      "546/546 [==============================] - 3s 5ms/step - loss: 0.2320 - accuracy: 0.8974 - val_loss: 0.3431 - val_accuracy: 0.8541\n",
      "Epoch 173/500\n",
      "546/546 [==============================] - 3s 5ms/step - loss: 0.2299 - accuracy: 0.8986 - val_loss: 0.3470 - val_accuracy: 0.8517\n",
      "Epoch 174/500\n",
      "546/546 [==============================] - 3s 5ms/step - loss: 0.2261 - accuracy: 0.9005 - val_loss: 0.3436 - val_accuracy: 0.8545\n",
      "Epoch 175/500\n",
      "546/546 [==============================] - 3s 5ms/step - loss: 0.2243 - accuracy: 0.9015 - val_loss: 0.3429 - val_accuracy: 0.8559\n",
      "Epoch 176/500\n",
      "546/546 [==============================] - 3s 5ms/step - loss: 0.2274 - accuracy: 0.9000 - val_loss: 0.3438 - val_accuracy: 0.8523\n",
      "Epoch 177/500\n",
      "546/546 [==============================] - 3s 5ms/step - loss: 0.2250 - accuracy: 0.9012 - val_loss: 0.3489 - val_accuracy: 0.8524\n",
      "Epoch 178/500\n",
      "546/546 [==============================] - 3s 5ms/step - loss: 0.2264 - accuracy: 0.9010 - val_loss: 0.3247 - val_accuracy: 0.8600\n",
      "Epoch 179/500\n",
      "546/546 [==============================] - 3s 5ms/step - loss: 0.2227 - accuracy: 0.9023 - val_loss: 0.3299 - val_accuracy: 0.8587\n",
      "Epoch 180/500\n",
      "546/546 [==============================] - 3s 5ms/step - loss: 0.2228 - accuracy: 0.9023 - val_loss: 0.3341 - val_accuracy: 0.8560\n",
      "Epoch 181/500\n",
      "546/546 [==============================] - 3s 5ms/step - loss: 0.2216 - accuracy: 0.9034 - val_loss: 0.3569 - val_accuracy: 0.8495\n",
      "Epoch 182/500\n",
      "546/546 [==============================] - 3s 5ms/step - loss: 0.2267 - accuracy: 0.9003 - val_loss: 0.3481 - val_accuracy: 0.8520\n",
      "Epoch 183/500\n",
      "546/546 [==============================] - 3s 5ms/step - loss: 0.2150 - accuracy: 0.9059 - val_loss: 0.3411 - val_accuracy: 0.8532\n",
      "Epoch 184/500\n",
      "546/546 [==============================] - 3s 5ms/step - loss: 0.2170 - accuracy: 0.9058 - val_loss: 0.3354 - val_accuracy: 0.8567\n",
      "Epoch 185/500\n",
      "546/546 [==============================] - 3s 5ms/step - loss: 0.2204 - accuracy: 0.9033 - val_loss: 0.3583 - val_accuracy: 0.8495\n",
      "Epoch 186/500\n",
      "546/546 [==============================] - 3s 5ms/step - loss: 0.2169 - accuracy: 0.9050 - val_loss: 0.3391 - val_accuracy: 0.8576\n",
      "Epoch 187/500\n",
      "546/546 [==============================] - 3s 5ms/step - loss: 0.2179 - accuracy: 0.9045 - val_loss: 0.3454 - val_accuracy: 0.8541\n",
      "Epoch 188/500\n",
      "546/546 [==============================] - 3s 5ms/step - loss: 0.2167 - accuracy: 0.9055 - val_loss: 0.3566 - val_accuracy: 0.8504\n",
      "Epoch 189/500\n",
      "546/546 [==============================] - 3s 5ms/step - loss: 0.2145 - accuracy: 0.9066 - val_loss: 0.3299 - val_accuracy: 0.8591\n",
      "Epoch 190/500\n",
      "546/546 [==============================] - 3s 5ms/step - loss: 0.2161 - accuracy: 0.9058 - val_loss: 0.3644 - val_accuracy: 0.8465\n",
      "Epoch 191/500\n",
      "546/546 [==============================] - 3s 5ms/step - loss: 0.2174 - accuracy: 0.9052 - val_loss: 0.3444 - val_accuracy: 0.8561\n",
      "Epoch 192/500\n",
      "546/546 [==============================] - 3s 5ms/step - loss: 0.2141 - accuracy: 0.9074 - val_loss: 0.3429 - val_accuracy: 0.8564\n",
      "Epoch 193/500\n",
      "546/546 [==============================] - 3s 5ms/step - loss: 0.2154 - accuracy: 0.9063 - val_loss: 0.4258 - val_accuracy: 0.8288\n",
      "Epoch 194/500\n",
      "546/546 [==============================] - 3s 5ms/step - loss: 0.2121 - accuracy: 0.9081 - val_loss: 0.3417 - val_accuracy: 0.8588\n",
      "Epoch 195/500\n",
      "546/546 [==============================] - 3s 5ms/step - loss: 0.2104 - accuracy: 0.9083 - val_loss: 0.3510 - val_accuracy: 0.8502\n",
      "Epoch 196/500\n",
      "546/546 [==============================] - 3s 5ms/step - loss: 0.2098 - accuracy: 0.9087 - val_loss: 0.3458 - val_accuracy: 0.8537\n",
      "Epoch 197/500\n",
      "546/546 [==============================] - 3s 5ms/step - loss: 0.2115 - accuracy: 0.9084 - val_loss: 0.3613 - val_accuracy: 0.8542\n",
      "Epoch 198/500\n",
      "546/546 [==============================] - 3s 5ms/step - loss: 0.2105 - accuracy: 0.9084 - val_loss: 0.3449 - val_accuracy: 0.8540\n",
      "Epoch 199/500\n",
      "546/546 [==============================] - 3s 5ms/step - loss: 0.2083 - accuracy: 0.9100 - val_loss: 0.3484 - val_accuracy: 0.8523\n",
      "Epoch 200/500\n",
      "546/546 [==============================] - 3s 5ms/step - loss: 0.2091 - accuracy: 0.9091 - val_loss: 0.3327 - val_accuracy: 0.8607\n",
      "Epoch 201/500\n",
      "546/546 [==============================] - 3s 5ms/step - loss: 0.2097 - accuracy: 0.9091 - val_loss: 0.3247 - val_accuracy: 0.8642\n",
      "Epoch 202/500\n",
      "546/546 [==============================] - 3s 5ms/step - loss: 0.2064 - accuracy: 0.9105 - val_loss: 0.3462 - val_accuracy: 0.8546\n",
      "Epoch 203/500\n",
      "546/546 [==============================] - 3s 5ms/step - loss: 0.2042 - accuracy: 0.9115 - val_loss: 0.3460 - val_accuracy: 0.8576\n",
      "Epoch 204/500\n",
      "546/546 [==============================] - 3s 5ms/step - loss: 0.2058 - accuracy: 0.9106 - val_loss: 0.3629 - val_accuracy: 0.8533\n",
      "Epoch 205/500\n",
      "546/546 [==============================] - 3s 5ms/step - loss: 0.2039 - accuracy: 0.9117 - val_loss: 0.3302 - val_accuracy: 0.8626\n",
      "Epoch 206/500\n",
      "546/546 [==============================] - 3s 5ms/step - loss: 0.2030 - accuracy: 0.9122 - val_loss: 0.3508 - val_accuracy: 0.8573\n",
      "Epoch 207/500\n",
      "546/546 [==============================] - 3s 5ms/step - loss: 0.2072 - accuracy: 0.9105 - val_loss: 0.3381 - val_accuracy: 0.8586\n",
      "Epoch 208/500\n",
      "546/546 [==============================] - 3s 5ms/step - loss: 0.2011 - accuracy: 0.9132 - val_loss: 0.3285 - val_accuracy: 0.8644\n",
      "Epoch 209/500\n",
      "546/546 [==============================] - 2s 5ms/step - loss: 0.1990 - accuracy: 0.9140 - val_loss: 0.3392 - val_accuracy: 0.8584\n",
      "Epoch 210/500\n",
      "546/546 [==============================] - 3s 5ms/step - loss: 0.2018 - accuracy: 0.9128 - val_loss: 0.3411 - val_accuracy: 0.8610\n",
      "Epoch 211/500\n",
      "546/546 [==============================] - 3s 5ms/step - loss: 0.2014 - accuracy: 0.9135 - val_loss: 0.3310 - val_accuracy: 0.8619\n",
      "Epoch 212/500\n",
      "546/546 [==============================] - 3s 5ms/step - loss: 0.2015 - accuracy: 0.9133 - val_loss: 0.3612 - val_accuracy: 0.8469\n",
      "Epoch 213/500\n",
      "546/546 [==============================] - 3s 5ms/step - loss: 0.1966 - accuracy: 0.9153 - val_loss: 0.3378 - val_accuracy: 0.8650\n",
      "Epoch 214/500\n",
      "546/546 [==============================] - 3s 5ms/step - loss: 0.2009 - accuracy: 0.9131 - val_loss: 0.3392 - val_accuracy: 0.8652\n",
      "Epoch 215/500\n",
      "546/546 [==============================] - 3s 5ms/step - loss: 0.1976 - accuracy: 0.9146 - val_loss: 0.3993 - val_accuracy: 0.8365\n",
      "Epoch 216/500\n",
      "546/546 [==============================] - 3s 5ms/step - loss: 0.1954 - accuracy: 0.9159 - val_loss: 0.3228 - val_accuracy: 0.8677\n",
      "Epoch 217/500\n",
      "546/546 [==============================] - 3s 5ms/step - loss: 0.1963 - accuracy: 0.9153 - val_loss: 0.3737 - val_accuracy: 0.8525\n",
      "Epoch 218/500\n",
      "546/546 [==============================] - 3s 5ms/step - loss: 0.1982 - accuracy: 0.9146 - val_loss: 0.3523 - val_accuracy: 0.8586\n",
      "Epoch 219/500\n",
      "546/546 [==============================] - 3s 5ms/step - loss: 0.1935 - accuracy: 0.9168 - val_loss: 0.3493 - val_accuracy: 0.8598\n",
      "Epoch 220/500\n",
      "546/546 [==============================] - 3s 5ms/step - loss: 0.1946 - accuracy: 0.9165 - val_loss: 0.3330 - val_accuracy: 0.8645\n",
      "Epoch 221/500\n",
      "546/546 [==============================] - 3s 5ms/step - loss: 0.1942 - accuracy: 0.9164 - val_loss: 0.3452 - val_accuracy: 0.8630\n",
      "Epoch 222/500\n",
      "546/546 [==============================] - 3s 5ms/step - loss: 0.1922 - accuracy: 0.9177 - val_loss: 0.3623 - val_accuracy: 0.8537\n",
      "Epoch 223/500\n",
      "546/546 [==============================] - 3s 5ms/step - loss: 0.1918 - accuracy: 0.9178 - val_loss: 0.3378 - val_accuracy: 0.8625\n",
      "Epoch 224/500\n",
      "546/546 [==============================] - 3s 5ms/step - loss: 0.1955 - accuracy: 0.9159 - val_loss: 0.3390 - val_accuracy: 0.8600\n",
      "Epoch 225/500\n",
      "546/546 [==============================] - 3s 5ms/step - loss: 0.1918 - accuracy: 0.9182 - val_loss: 0.3366 - val_accuracy: 0.8639\n",
      "Epoch 226/500\n",
      "546/546 [==============================] - 3s 5ms/step - loss: 0.1905 - accuracy: 0.9186 - val_loss: 0.3275 - val_accuracy: 0.8659\n",
      "Epoch 227/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "546/546 [==============================] - 3s 5ms/step - loss: 0.1864 - accuracy: 0.9200 - val_loss: 0.3305 - val_accuracy: 0.8679\n",
      "Epoch 228/500\n",
      "546/546 [==============================] - 3s 5ms/step - loss: 0.1934 - accuracy: 0.9172 - val_loss: 0.3532 - val_accuracy: 0.8596\n",
      "Epoch 229/500\n",
      "546/546 [==============================] - 3s 5ms/step - loss: 0.1867 - accuracy: 0.9202 - val_loss: 0.3328 - val_accuracy: 0.8678\n",
      "Epoch 230/500\n",
      "546/546 [==============================] - 3s 5ms/step - loss: 0.1886 - accuracy: 0.9196 - val_loss: 0.3467 - val_accuracy: 0.8617\n",
      "Epoch 231/500\n",
      "546/546 [==============================] - 3s 5ms/step - loss: 0.1894 - accuracy: 0.9189 - val_loss: 0.3211 - val_accuracy: 0.8689\n",
      "Epoch 232/500\n",
      "546/546 [==============================] - 3s 5ms/step - loss: 0.1872 - accuracy: 0.9202 - val_loss: 0.3354 - val_accuracy: 0.8650\n",
      "Epoch 233/500\n",
      "546/546 [==============================] - 3s 5ms/step - loss: 0.1871 - accuracy: 0.9203 - val_loss: 0.3182 - val_accuracy: 0.8708\n",
      "Epoch 234/500\n",
      "546/546 [==============================] - 3s 5ms/step - loss: 0.1841 - accuracy: 0.9218 - val_loss: 0.3282 - val_accuracy: 0.8709\n",
      "Epoch 235/500\n",
      "546/546 [==============================] - 3s 5ms/step - loss: 0.1872 - accuracy: 0.9198 - val_loss: 0.3261 - val_accuracy: 0.8672\n",
      "Epoch 236/500\n",
      "546/546 [==============================] - 3s 5ms/step - loss: 0.1854 - accuracy: 0.9209 - val_loss: 0.3394 - val_accuracy: 0.8625\n",
      "Epoch 237/500\n",
      "546/546 [==============================] - 3s 5ms/step - loss: 0.1860 - accuracy: 0.9204 - val_loss: 0.3268 - val_accuracy: 0.8672\n",
      "Epoch 238/500\n",
      "546/546 [==============================] - 3s 5ms/step - loss: 0.1830 - accuracy: 0.9219 - val_loss: 0.3293 - val_accuracy: 0.8678\n",
      "Epoch 239/500\n",
      "546/546 [==============================] - 3s 5ms/step - loss: 0.1833 - accuracy: 0.9218 - val_loss: 0.3397 - val_accuracy: 0.8660\n",
      "Epoch 240/500\n",
      "546/546 [==============================] - 3s 5ms/step - loss: 0.1853 - accuracy: 0.9209 - val_loss: 0.3232 - val_accuracy: 0.8697\n",
      "Epoch 241/500\n",
      "546/546 [==============================] - 3s 5ms/step - loss: 0.1783 - accuracy: 0.9243 - val_loss: 0.3255 - val_accuracy: 0.8699\n",
      "Epoch 242/500\n",
      "546/546 [==============================] - 3s 5ms/step - loss: 0.1819 - accuracy: 0.9229 - val_loss: 0.3451 - val_accuracy: 0.8632\n",
      "Epoch 243/500\n",
      "546/546 [==============================] - 3s 5ms/step - loss: 0.1842 - accuracy: 0.9217 - val_loss: 0.3144 - val_accuracy: 0.8731\n",
      "Epoch 244/500\n",
      "546/546 [==============================] - 3s 5ms/step - loss: 0.1773 - accuracy: 0.9245 - val_loss: 0.3858 - val_accuracy: 0.8429\n",
      "Epoch 245/500\n",
      "546/546 [==============================] - 3s 5ms/step - loss: 0.1808 - accuracy: 0.9229 - val_loss: 0.3246 - val_accuracy: 0.8723\n",
      "Epoch 246/500\n",
      "546/546 [==============================] - 3s 5ms/step - loss: 0.1785 - accuracy: 0.9238 - val_loss: 0.3262 - val_accuracy: 0.8674\n",
      "Epoch 247/500\n",
      "546/546 [==============================] - 3s 5ms/step - loss: 0.1788 - accuracy: 0.9234 - val_loss: 0.3720 - val_accuracy: 0.8535\n",
      "Epoch 248/500\n",
      "546/546 [==============================] - 3s 5ms/step - loss: 0.1759 - accuracy: 0.9249 - val_loss: 0.3378 - val_accuracy: 0.8681\n",
      "Epoch 249/500\n",
      "546/546 [==============================] - 3s 5ms/step - loss: 0.1788 - accuracy: 0.9239 - val_loss: 0.3381 - val_accuracy: 0.8682\n",
      "Epoch 250/500\n",
      "546/546 [==============================] - 3s 5ms/step - loss: 0.1795 - accuracy: 0.9239 - val_loss: 0.3342 - val_accuracy: 0.8722\n",
      "Epoch 251/500\n",
      "546/546 [==============================] - 3s 5ms/step - loss: 0.1750 - accuracy: 0.9255 - val_loss: 0.3352 - val_accuracy: 0.8665\n",
      "Epoch 252/500\n",
      "546/546 [==============================] - 3s 5ms/step - loss: 0.1749 - accuracy: 0.9260 - val_loss: 0.3190 - val_accuracy: 0.8745\n",
      "Epoch 253/500\n",
      "546/546 [==============================] - 3s 5ms/step - loss: 0.1748 - accuracy: 0.9256 - val_loss: 0.3325 - val_accuracy: 0.8696\n",
      "Epoch 254/500\n",
      "546/546 [==============================] - 3s 5ms/step - loss: 0.1791 - accuracy: 0.9238 - val_loss: 0.3406 - val_accuracy: 0.8687\n",
      "Epoch 255/500\n",
      "546/546 [==============================] - 3s 5ms/step - loss: 0.1718 - accuracy: 0.9271 - val_loss: 0.3298 - val_accuracy: 0.8721\n",
      "Epoch 256/500\n",
      "546/546 [==============================] - 3s 5ms/step - loss: 0.1756 - accuracy: 0.9252 - val_loss: 0.3222 - val_accuracy: 0.8732\n",
      "Epoch 257/500\n",
      "546/546 [==============================] - 3s 5ms/step - loss: 0.1712 - accuracy: 0.9276 - val_loss: 0.3265 - val_accuracy: 0.8700\n",
      "Epoch 258/500\n",
      "546/546 [==============================] - 3s 5ms/step - loss: 0.1729 - accuracy: 0.9267 - val_loss: 0.3294 - val_accuracy: 0.8732\n",
      "Epoch 259/500\n",
      "546/546 [==============================] - 3s 5ms/step - loss: 0.1744 - accuracy: 0.9261 - val_loss: 0.3287 - val_accuracy: 0.8741\n",
      "Epoch 260/500\n",
      "546/546 [==============================] - 3s 5ms/step - loss: 0.1725 - accuracy: 0.9271 - val_loss: 0.3487 - val_accuracy: 0.8630\n",
      "Epoch 261/500\n",
      "546/546 [==============================] - 3s 5ms/step - loss: 0.1714 - accuracy: 0.9275 - val_loss: 0.3245 - val_accuracy: 0.8749\n",
      "Epoch 262/500\n",
      "546/546 [==============================] - 3s 5ms/step - loss: 0.1706 - accuracy: 0.9281 - val_loss: 0.3973 - val_accuracy: 0.8461\n",
      "Epoch 263/500\n",
      "546/546 [==============================] - 3s 5ms/step - loss: 0.1697 - accuracy: 0.9284 - val_loss: 0.3364 - val_accuracy: 0.8715\n",
      "Epoch 264/500\n",
      "546/546 [==============================] - 3s 5ms/step - loss: 0.1714 - accuracy: 0.9277 - val_loss: 0.3192 - val_accuracy: 0.8755\n",
      "Epoch 265/500\n",
      "546/546 [==============================] - 3s 5ms/step - loss: 0.1711 - accuracy: 0.9275 - val_loss: 0.3301 - val_accuracy: 0.8727\n",
      "Epoch 266/500\n",
      "546/546 [==============================] - 3s 5ms/step - loss: 0.1666 - accuracy: 0.9294 - val_loss: 0.3204 - val_accuracy: 0.8775\n",
      "Epoch 267/500\n",
      "546/546 [==============================] - 3s 5ms/step - loss: 0.1698 - accuracy: 0.9285 - val_loss: 0.3312 - val_accuracy: 0.8697\n",
      "Epoch 268/500\n",
      "546/546 [==============================] - 2s 4ms/step - loss: 0.1665 - accuracy: 0.9297 - val_loss: 0.3205 - val_accuracy: 0.8756\n",
      "Epoch 269/500\n",
      "546/546 [==============================] - 3s 5ms/step - loss: 0.1638 - accuracy: 0.9309 - val_loss: 0.3713 - val_accuracy: 0.8570\n",
      "Epoch 270/500\n",
      "546/546 [==============================] - 3s 5ms/step - loss: 0.1681 - accuracy: 0.9288 - val_loss: 0.3258 - val_accuracy: 0.8737\n",
      "Epoch 271/500\n",
      "546/546 [==============================] - 3s 5ms/step - loss: 0.1647 - accuracy: 0.9305 - val_loss: 0.3240 - val_accuracy: 0.8768\n",
      "Epoch 272/500\n",
      "546/546 [==============================] - 3s 5ms/step - loss: 0.1701 - accuracy: 0.9281 - val_loss: 0.3347 - val_accuracy: 0.8694\n",
      "Epoch 273/500\n",
      "546/546 [==============================] - 3s 5ms/step - loss: 0.1639 - accuracy: 0.9308 - val_loss: 0.3219 - val_accuracy: 0.8762\n",
      "Training Time:  741.1256296634674 seconds\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "history = ann_model.fit(X_train, y_train,\n",
    "                         batch_size=batch_size,\n",
    "                         epochs=epochs,\n",
    "                         validation_split=0.1,\n",
    "                         callbacks=[checkpoint, early_stopping],  \n",
    "                         verbose=1)\n",
    "\n",
    "end_time = time.time()\n",
    "\n",
    "training_time = end_time - start_time\n",
    "print(\"Training Time: \", training_time, \"seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f19ba408-fb43-4e74-8ebe-0ae91cedcbd1",
   "metadata": {},
   "source": [
    "# Saving the model and training history "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1596dc98-c558-428e-8c83-051826b10a25",
   "metadata": {},
   "outputs": [],
   "source": [
    "ann_model.save('ANN_Architecture_22_Features.h5')\n",
    "np.save('ANN_history_22_Features.npy', history.history)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "233e5813",
   "metadata": {},
   "source": [
    "# 5. Model Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fac60871",
   "metadata": {},
   "source": [
    "# Importing Libraries - Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e546835",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bd8e2a4",
   "metadata": {},
   "source": [
    "# Plotting Loss and Accuracy Curve"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "decc0953",
   "metadata": {},
   "source": [
    "### Loss Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de1067f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=[8,6])\n",
    "\n",
    "plt.plot(history.history['loss'], 'r', linewidth=3.0)\n",
    "plt.plot(history.history['val_loss'], 'b', linewidth=3.0)\n",
    "\n",
    "plt.xlabel('Epochs', fontsize=16)\n",
    "plt.ylabel('Loss', fontsize=16)\n",
    "\n",
    "plt.legend(['Training Loss', 'Validation Loss'], fontsize=18)\n",
    "plt.title('Loss Curve of Artificial Neural Network - 22 Features', fontsize=16)\n",
    "\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13d1eeae",
   "metadata": {},
   "source": [
    "### Accuracy Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8aa65d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=[8,6])\n",
    "\n",
    "plt.plot(history.history['accuracy'], 'r', linewidth=3.0)\n",
    "plt.plot(history.history['val_accuracy'], 'b', linewidth=3.0)\n",
    "\n",
    "plt.xlabel('Epochs', fontsize=16)\n",
    "plt.ylabel('Accuracy', fontsize=16)\n",
    "\n",
    "plt.legend(['Training Accuracy', 'Validation Accuracy'], fontsize=18)\n",
    "plt.title('Accuracy Curve of Artificial Neural Network - 22 Features', fontsize=16)\n",
    "\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dc04b9e",
   "metadata": {},
   "source": [
    "###  Make predictions on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "092a3186",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = ann_model.predict(X_test)\n",
    "y_pred = (y_pred > 0.5).astype(int).flatten()  # Convert probabilities to classes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e73cfada",
   "metadata": {},
   "source": [
    "# Classification Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50511da1",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss, test_accuracy = ann_model.evaluate(X_test, y_test, verbose=0)\n",
    "print(f'Test accuracy: {test_accuracy:.2f}, Test loss: {test_loss:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aa60e39",
   "metadata": {},
   "outputs": [],
   "source": [
    "classification_report = classification_report(y_test, y_pred)\n",
    "print(classification_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8585389",
   "metadata": {},
   "source": [
    "# Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dce2fde",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_labels = [\"Alert\", \"Drowsy\"]\n",
    "\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "accuracy = accuracy_score(y_test, y_pred) * 100\n",
    "\n",
    "# Plot confusion matrix\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', cbar=True, xticklabels=class_labels, yticklabels=class_labels, linewidths=.5)\n",
    "\n",
    "plt.title(f'Confusion Matrix ANN - 22 (Accuracy: {accuracy:.2f}%)', fontsize=16)\n",
    "\n",
    "plt.xlabel('Predicted Label', fontsize=14)\n",
    "plt.ylabel('True Label', fontsize=14)\n",
    "\n",
    "plt.xticks(rotation=0, fontsize=12)  \n",
    "plt.yticks(rotation=0, fontsize=12)  \n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f343fa0",
   "metadata": {},
   "source": [
    "# Evaluation Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2de39a2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate accuracy, precision, recall, F1-score, AUC-ROC\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "auc_roc = roc_auc_score(y_test, y_pred)\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1-score:\", f1)\n",
    "print(\"AUC-ROC:\", auc_roc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af0c07a2",
   "metadata": {},
   "source": [
    "# Receiver Operating Characteristic (ROC) Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40f0baa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_data = {}\n",
    "\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_pred)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "roc_data['ANN - 22'] = {'fpr': fpr, 'tpr': tpr, 'roc_auc': roc_auc}\n",
    "\n",
    "# Plotting ROC Curves \n",
    "plt.figure(figsize=(10, 8))\n",
    "for name, data in roc_data.items():\n",
    "    plt.plot(data['fpr'], data['tpr'], lw=2, label=f'{name} (AUC = {data[\"roc_auc\"]:.2f})')\n",
    "\n",
    "plt.plot([0, 1], [0, 1], linestyle='--', color='gray', lw=2, label='Random Guessing')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate', fontsize=14)\n",
    "plt.ylabel('True Positive Rate', fontsize=14)\n",
    "plt.title('Receiver Operating Characteristic (ROC) Curve', fontsize=16)\n",
    "plt.legend(loc='lower right', fontsize=12)\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45ef87ba-558b-4879-83d6-10fee10dc60f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67845ad1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "976ab65a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cf9f05a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
